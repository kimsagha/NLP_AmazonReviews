{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "Data structure and content\n",
    "* 3 columns:\n",
    "    1. Rating: the rating given for the review\n",
    "    2. Summary: summary of the complete review text\n",
    "    3. Text: the complete text of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Reviews.csv')\n",
    "df = df.rename(columns={'Score': 'Rating'})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of different ratings:', len(pd.unique(df['Rating'])))\n",
    "ratings = pd.unique(df['Rating'])\n",
    "ratings.sort(axis=0)\n",
    "print('Ratings:', ratings)\n",
    "\n",
    "rating_frequencies = []\n",
    "for i in range(1,6):\n",
    "    rating_frequencies.append(df[df.Rating == i].shape[0])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.set_title('Occurrences of each Rating')\n",
    "plt.xlabel('Ratings')\n",
    "plt.ylabel('Frequencies')\n",
    "bars = ax.bar(ratings,rating_frequencies)\n",
    "for bar in bars:\n",
    "  height = bar.get_height()\n",
    "  label_x_pos = bar.get_x() + bar.get_width() / 2\n",
    "  ax.text(label_x_pos, height, s=f'{height}', ha='center', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of data points:', len(df.index))\n",
    "print('Number of null values in each column:')\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No null values in important columns Rating and Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 27/568454 rows have null values so remove those rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of data points:', len(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change all ratings above 3 to positive and below 3 to negative. Remove reviews with a neutral rating of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df.Rating == 3].index)\n",
    "df['Rating'] = df['Rating'].apply(lambda x : ('pos') if (x > 3) else ('neg'))\n",
    "print('Number of data points:', len(df.index))\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Checking types of df columns:')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling data to fix class imbalance and to decrease processing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pos = df.loc[df['Rating'] == 'pos'].sample(5000, random_state=1)\n",
    "# df_neg = df.loc[df['Rating'] == 'neg'].sample(5000, random_state=1)\n",
    "df_pos = df.loc[df['Rating'] == 'pos'].sample(df[df.Rating == 'neg'].shape[0], random_state=1)\n",
    "df_neg = df.loc[df['Rating'] == 'neg']\n",
    "df = pd.concat([df_pos, df_neg])\n",
    "df = df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset into 67% train and 33% test data. Stratify to keep the same class distribution in the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['Text'],\n",
    "                                                    df['Rating'],\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=df['Rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize string data: convert text in training and test sets to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veYeah ctorizer = CountVectorizer(binary=True)\n",
    "\n",
    "x_train_vectorized = vectorizer.fit_transform(x_train)\n",
    "x_test_vectorized = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(x_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "print(\"Accuracy:\", clf.score(x_test_vectorized, y_test))\n",
    "y_pred = clf.predict(x_test_vectorized)\n",
    "print('F1 score:', f1_score(y_test, y_pred, average=None, labels=['pos', 'neg']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter tuning and exploring other models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
